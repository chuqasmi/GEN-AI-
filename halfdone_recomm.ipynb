{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbgYQWSQogFs89YVSO/992",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chuqasmi/GEN-AI-/blob/main/halfdone_recomm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XqRKK2q1A9nO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphDataset(Dataset):\n",
        "    def __init__(self, data, u_items_list, u_user_list, u_users_items_list, i_users_list):\n",
        "        self.data = data\n",
        "        self.u_items_list = u_items_list\n",
        "        self.u_users_list = u_user_list\n",
        "        self.u_users_items_list = u_users_items_list\n",
        "        self.i_users_list = i_users_list\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        uid = self.data[index][0]\n",
        "        iid = self.data[index][1]\n",
        "        label = self.data[index][2]\n",
        "        u_items = self.u_items_list[uid]\n",
        "        u_users = self.u_users_list[uid]\n",
        "        u_users_items = self.u_users_items_list[uid]\n",
        "        i_users = self.i_users_list[iid]\n",
        "\n",
        "        return (uid, iid, label), u_items, u_users, u_users_items, i_users\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "7KyBmElVBcpK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truncate_len = 45\n",
        "\n",
        "def collate_fn(batch_data):\n",
        "\n",
        "    uids, iids, labels = [], [], []\n",
        "    u_items, u_users, u_users_items, i_users = [], [], [], []\n",
        "    u_items_len, u_users_len, i_users_len = [], [], []\n",
        "\n",
        "    for data, u_items_u, u_users_u, u_users_items_u, i_users_i in batch_data:\n",
        "\n",
        "        (uid, iid, label) = data\n",
        "        uids.append(uid)\n",
        "        iids.append(iid)\n",
        "        labels.append(label)\n",
        "\n",
        "        # user-items\n",
        "        if len(u_items_u) <= truncate_len:\n",
        "            u_items.append(u_items_u)\n",
        "        else:\n",
        "            u_items.append(random.sample(u_items_u, truncate_len))\n",
        "        u_items_len.append(min(len(u_items_u), truncate_len))\n",
        "\n",
        "        # user-users and user-users-items\n",
        "        if len(u_users_u) <= truncate_len:\n",
        "            u_users.append(u_users_u)\n",
        "            u_u_items = []\n",
        "            for uui in u_users_items_u:\n",
        "                if len(uui) < truncate_len:\n",
        "                    u_u_items.append(uui)\n",
        "                else:\n",
        "                    u_u_items.append(random.sample(uui, truncate_len))\n",
        "            u_users_items.append(u_u_items)\n",
        "        else:\n",
        "            sample_index = random.sample(list(range(len(u_users_u))), truncate_len)\n",
        "            u_users.append([u_users_u[si] for si in sample_index])\n",
        "\n",
        "            u_users_items_u_tr = [u_users_items_u[si] for si in sample_index]\n",
        "            u_u_items = []\n",
        "            for uui in u_users_items_u_tr:\n",
        "                if len(uui) < truncate_len:\n",
        "                    u_u_items.append(uui)\n",
        "                else:\n",
        "                    u_u_items.append(random.sample(uui, truncate_len))\n",
        "            u_users_items.append(u_u_items)\n",
        "\n",
        "        u_users_len.append(min(len(u_users_u), truncate_len))\n",
        "\n",
        "        # item-users\n",
        "        if len(i_users_i) <= truncate_len:\n",
        "            i_users.append(i_users_i)\n",
        "        else:\n",
        "            i_users.append(random.sample(i_users_i, truncate_len))\n",
        "        i_users_len.append(min(len(i_users_i), truncate_len))\n",
        "\n",
        "    batch_size = len(batch_data)\n",
        "\n",
        "    # padding\n",
        "    u_items_maxlen = max(u_items_len)\n",
        "    u_users_maxlen = max(u_users_len)\n",
        "    i_users_maxlen = max(i_users_len)\n",
        "\n",
        "    u_item_pad = torch.zeros([batch_size, u_items_maxlen, 2], dtype=torch.long)\n",
        "    for i, ui in enumerate(u_items):\n",
        "        u_item_pad[i, :len(ui), :] = torch.LongTensor(ui)\n",
        "\n",
        "    u_user_pad = torch.zeros([batch_size, u_users_maxlen], dtype=torch.long)\n",
        "    for i, uu in enumerate(u_users):\n",
        "        u_user_pad[i, :len(uu)] = torch.LongTensor(uu)\n",
        "\n",
        "    u_user_item_pad = torch.zeros([batch_size, u_users_maxlen, u_items_maxlen, 2], dtype=torch.long)\n",
        "    for i, uu_items in enumerate(u_users_items):\n",
        "        for j, ui in enumerate(uu_items):\n",
        "            u_user_item_pad[i, j, :len(ui), :] = torch.LongTensor(ui)\n",
        "\n",
        "    i_user_pad = torch.zeros([batch_size, i_users_maxlen, 2], dtype=torch.long)\n",
        "    for i, iu in enumerate(i_users):\n",
        "        i_user_pad[i, :len(iu), :] = torch.LongTensor(iu)\n",
        "\n",
        "    uids = torch.LongTensor(uids)\n",
        "    iids = torch.LongTensor(iids)\n",
        "    labels = torch.FloatTensor(labels)\n",
        "\n",
        "    return uids, iids, labels, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad"
      ],
      "metadata": {
        "id": "KgguCBy1BoV4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim//2, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_dim//2, output_dim, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)\n",
        "\n",
        "class Aggregator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Aggregator, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim, bias=True),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)\n",
        "\n",
        "\n",
        "class UserModel(nn.Module):\n",
        "    def __init__(self, emb_dim, user_emb, item_emb, rating_emb):\n",
        "        super(UserModel, self).__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.user_emb = user_emb\n",
        "        self.item_emb = item_emb\n",
        "        self.rating_emb = rating_emb\n",
        "\n",
        "        self.g_v = MLP(2*self.emb_dim, self.emb_dim)\n",
        "\n",
        "        self.user_item_attn = MLP(2*self.emb_dim, 1)\n",
        "        self.aggr_items = Aggregator(self.emb_dim, self.emb_dim)\n",
        "\n",
        "        self.user_user_attn = MLP(2*self.emb_dim, 1)\n",
        "        self.aggr_neighbors = Aggregator(self.emb_dim, self.emb_dim)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2*self.emb_dim, self.emb_dim, bias = True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.emb_dim, self.emb_dim, bias = True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.emb_dim, self.emb_dim, bias = True),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.eps = 1e-10\n",
        "\n",
        "    def forward(self, uids, u_item_pad, u_user_pad, u_user_item_pad):\n",
        "\n",
        "        q_a = self.item_emb(u_item_pad[:,:,0])\n",
        "        u_item_er = self.rating_emb(u_item_pad[:,:,1])\n",
        "        x_ia = self.g_v(torch.cat([q_a, u_item_er], dim=2).view(-1, 2*self.emb_dim)).view(q_a.size())\n",
        "        mask_u = torch.where(u_item_pad[:,:,0]>0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n",
        "        p_i = mask_u.unsqueeze(2).expand_as(x_ia) * self.user_emb(uids).unsqueeze(1).expand_as(x_ia)\n",
        "        alpha = self.user_item_attn(torch.cat([x_ia, p_i], dim=2).view(-1, 2*self.emb_dim)).view(mask_u.size())\n",
        "        alpha = torch.exp(alpha)*mask_u\n",
        "        alpha = alpha / (torch.sum(alpha, 1).unsqueeze(1).expand_as(alpha) + self.eps)\n",
        "        h_iI = self.aggr_items(torch.sum(alpha.unsqueeze(2).expand_as(x_ia) * x_ia, 1))\n",
        "\n",
        "\n",
        "        q_a_s = self.item_emb(u_user_item_pad[:,:,:,0])\n",
        "        u_user_item_er = self.rating_emb(u_user_item_pad[:,:,:,1])\n",
        "        x_ia_s = self.g_v(torch.cat([q_a_s, u_user_item_er], dim=2).view(-1, 2*self.emb_dim)).view(q_a_s.size())\n",
        "        mask_s = torch.where(u_user_item_pad[:,:,:,0]>0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n",
        "        p_i_s = mask_s.unsqueeze(3).expand_as(x_ia_s) * self.user_emb(u_user_pad).unsqueeze(2).expand_as(x_ia_s)\n",
        "        alpha_s = self.user_item_attn(torch.cat([x_ia_s, p_i_s], dim=3).view(-1, 2*self.emb_dim)).view(mask_s.size())\n",
        "        alpha_s = torch.exp(alpha_s)*mask_s\n",
        "        alpha_s = alpha_s / (torch.sum(alpha_s, 2).unsqueeze(2).expand_as(alpha_s) + self.eps)\n",
        "        h_oI_temp = torch.sum(alpha_s.unsqueeze(3).expand_as(x_ia_s) * x_ia_s, 2)\n",
        "        h_oI = self.aggr_items(h_oI_temp.view(-1, self.emb_dim)).view(h_oI_temp.size())\n",
        "\n",
        "        beta = self.user_user_attn(torch.cat([h_oI, self.user_emb(u_user_pad)], dim = 2).view(-1, 2 * self.emb_dim)).view(u_user_pad.size())\n",
        "        mask_su = torch.where(u_user_pad > 0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n",
        "        beta = torch.exp(beta) * mask_su\n",
        "        beta = beta / (torch.sum(beta, 1).unsqueeze(1).expand_as(beta) + self.eps)\n",
        "        h_iS = self.aggr_neighbors(torch.sum(beta.unsqueeze(2).expand_as(h_oI) * h_oI, 1))\n",
        "\n",
        "        h_i = self.mlp(torch.cat([h_iI, h_iS], dim = 1))\n",
        "\n",
        "        return h_i\n",
        "\n",
        "\n",
        "class ItemModel(nn.Module):\n",
        "    def __init__(self, emb_dim, user_emb, item_emb, rating_emb):\n",
        "        super(ItemModel, self).__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.user_emb = user_emb\n",
        "        self.item_emb = item_emb\n",
        "        self.rating_emb = rating_emb\n",
        "\n",
        "        self.g_u = MLP(2*self.emb_dim, self.emb_dim)\n",
        "\n",
        "        self.item_users_attn = MLP(2*self.emb_dim, 1)\n",
        "        self.aggr_users = Aggregator(self.emb_dim, self.emb_dim)\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.eps = 1e-10\n",
        "\n",
        "    def forward(self, iids, i_user_pad):\n",
        "\n",
        "        p_t = self.user_emb(i_user_pad[:,:,0])\n",
        "        i_user_er = self.rating_emb(i_user_pad[:,:,1])\n",
        "        mask_i = torch.where(i_user_pad[:,:,0] > 0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n",
        "        f_jt = self.g_u(torch.cat([p_t, i_user_er], dim = 2).view(-1, 2 * self.emb_dim)).view(p_t.size())\n",
        "        q_j = mask_i.unsqueeze(2).expand_as(f_jt) * self.item_emb(iids).unsqueeze(1).expand_as(f_jt)\n",
        "        mu_jt = self.item_users_attn(torch.cat([f_jt, q_j], dim = 2).view(-1, 2 * self.emb_dim)).view(mask_i.size())\n",
        "        mu_jt = torch.exp(mu_jt) * mask_i\n",
        "        mu_jt = mu_jt / (torch.sum(mu_jt, 1).unsqueeze(1).expand_as(mu_jt) + self.eps)\n",
        "\n",
        "        z_j = self.aggr_users(torch.sum(mu_jt.unsqueeze(2).expand_as(f_jt) * f_jt, 1))\n",
        "\n",
        "        return z_j\n",
        "\n",
        "\n",
        "class GraphRec(nn.Module):\n",
        "    def __init__(self, n_users, n_items, n_ratings, emb_dim = 64):\n",
        "        super(GraphRec, self).__init__()\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.n_ratings = n_ratings\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.user_emb = nn.Embedding(self.n_users, self.emb_dim, padding_idx=0)\n",
        "        self.item_emb = nn.Embedding(self.n_items, self.emb_dim, padding_idx=0)\n",
        "        self.rating_emb = nn.Embedding(self.n_ratings, self.emb_dim, padding_idx=0)\n",
        "\n",
        "        self.user_model = UserModel(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n",
        "        self.item_model = ItemModel(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2*self.emb_dim, self.emb_dim, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.emb_dim, self.emb_dim, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.emb_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, uids, iids, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad):\n",
        "\n",
        "        h_i = self.user_model(uids, u_item_pad, u_user_pad, u_user_item_pad)\n",
        "        z_j = self.item_model(iids, i_user_pad)\n",
        "\n",
        "        r_ij = self.mlp(torch.cat([h_i, z_j], dim=1))\n",
        "\n",
        "        return r_ij"
      ],
      "metadata": {
        "id": "YddZj_JcB4de"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device - ' + str(device))\n",
        "batch_size = 128\n",
        "embed_dim = 64\n",
        "learning_rate = 0.0001\n",
        "n_epochs = 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oda94fnkB_As",
        "outputId": "a70949a4-cc12-4859-bef1-a845dd630a35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device - cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('C:\\\\Users\\\\Raheem Laptops\\\\Desktop\\\\research\\\\datasets\\\\car_prices', 'rb') as f:\n",
        "    train_set = pickle.load(f)\n",
        "    valid_set = pickle.load(f)\n",
        "    test_set = pickle.load(f)\n",
        "\n",
        "with open('r'C:\\Users\\Raheem Laptops\\Desktop\\research\\datasets\\car_prices')\n",
        "', 'rb') as f:\n",
        "    u_items_list = pickle.load(f)\n",
        "    u_users_list = pickle.load(f)\n",
        "    u_users_items_list = pickle.load(f)\n",
        "    i_users_list = pickle.load(f)\n",
        "    (user_count, item_count, rate_count) = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "wAyslZnwIM_7",
        "outputId": "7fe8f3e4-4573-40e9-932d-4bb5b02e4681"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-16-8fc7250e4459>, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-8fc7250e4459>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    with open('r'C:\\Users\\Raheem Laptops\\Desktop\\research\\datasets\\car_prices')\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kzRzb1NvHb2d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jgCiO-P4Jeux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}